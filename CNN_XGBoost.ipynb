{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a518b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import layers,Sequential\n",
    "import xgboost\n",
    "import glob\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aefb194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"..\\\\Dataset\\\\datasets\\\\train\\\\*\\\\*\"\n",
    "validation_path = \"..\\\\Dataset\\\\datasets\\\\validation\\\\*\\\\*\"\n",
    "test_path = \"..\\\\Dataset\\\\datasets\\\\test\\\\*\\\\*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d2c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weigh_calculator():\n",
    "    cardboard_number = len(os.listdir('..\\\\Dataset\\\\datasets\\\\train'+ os.sep + f'cardboard'))\n",
    "    glass_number = len(os.listdir('..\\\\Dataset\\\\datasets\\\\train'+ os.sep + f'glass'))\n",
    "    metal_number = len(os.listdir('..\\\\Dataset\\\\datasets\\\\train'+ os.sep + f'metal'))\n",
    "    paper_number = len(os.listdir('..\\\\Dataset\\\\datasets\\\\train'+ os.sep + f'paper'))\n",
    "    plastic_number = len(os.listdir('..\\\\Dataset\\\\datasets\\\\train'+ os.sep + f'plastic'))\n",
    "    trash_number = len(os.listdir('..\\\\Dataset\\\\datasets\\\\train'+ os.sep + f'trash'))\n",
    "    cardboard_wight =1/((cardboard_number) * (1/glass_number + 1/metal_number + 1/paper_number + 1/plastic_number + 1/trash_number))\n",
    "    glass_wight =1/((glass_number) * (1/cardboard_number + 1/metal_number + 1/paper_number + 1/plastic_number + 1/trash_number))\n",
    "    metal_wight =1/((metal_number) * (1/glass_number + 1/cardboard_number + 1/paper_number + 1/plastic_number + 1/trash_number))\n",
    "    paper_wight =1/((paper_number) * (1/glass_number + 1/metal_number + 1/cardboard_number + 1/plastic_number + 1/trash_number))\n",
    "    plastic_wight =1/((plastic_number) * (1/glass_number + 1/metal_number + 1/paper_number + 1/cardboard_number + 1/trash_number))\n",
    "    trash_wight =1/((trash_number) * (1/glass_number + 1/metal_number + 1/paper_number + 1/plastic_number + 1/cardboard_number))\n",
    "    return {0:cardboard_wight, 1:glass_wight, 2:metal_wight, 3:paper_wight, 4:plastic_wight, 5:trash_wight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcbf600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path):\n",
    "    my_list = list(glob.glob(path))\n",
    "    data= []\n",
    "    label = []\n",
    "    for item in my_list:\n",
    "        label.append(item.split(os.sep)[-2])\n",
    "        image = cv2.imread(item,cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image,(224,224))\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        data.append(image)\n",
    "    return np.array(data),np.array(label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a2685ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = Sequential([\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(factor=(-0.3, 0.3),fill_mode='wrap',interpolation='bilinear'),\n",
    "    layers.RandomZoom(height_factor=(0.2,0.4),width_factor=(0.2,0.4),fill_mode='wrap',interpolation='bilinear'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ff4bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = create_dataset(train_path)\n",
    "x_val, y_val = create_dataset(validation_path)\n",
    "x_test, y_test = create_dataset(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3e7048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_val = x_val /255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f108e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e76acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_val = label_encoder.fit_transform(y_val)\n",
    "y_test = label_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69fc2486",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = VGG16(weights='imagenet',include_top= False, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ce3c620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6af53a08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "862b55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = Sequential([data_augmentation,vgg16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ff62e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1768, 7, 7, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = feature_extractor.predict(x_train)\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a2aa9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d1bc7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1768, 25088)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = train_features.reshape(train_features.shape[0],-1)\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44830e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weight = weigh_calculator()\n",
    "weights = np.zeros(len(y_train))\n",
    "for i in range(0,6):\n",
    "    weights[y_train==i] = train_weight[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a496797",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = xgboost.DMatrix(data=train_features,label= y_train,weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38258880",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "505c2ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_features = feature_extractor.predict(x_val)\n",
    "validation_features = validation_features.reshape(validation_features.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8559375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = xgboost.DMatrix(data= validation_features,label= y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c24ad65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del validation_features\n",
    "del x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a4549c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_1 = {\n",
    "    'booster': 'gbtree',\n",
    "    'max_depth': 15, \n",
    "    'learning_rate': 0.25,\n",
    "    'subsample': 0.8,\n",
    "    'rate_drop': 0.2,\n",
    "    'n_estimators': 1000,\n",
    "    'min_chiled_weight': 3,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 6,\n",
    "    'gpu_id' : 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58c5baff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:55:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"min_chiled_weight\", \"n_estimators\", \"rate_drop\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:55:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\teval-mlogloss:1.63914\n",
      "[1]\teval-mlogloss:1.51536\n",
      "[2]\teval-mlogloss:1.42114\n",
      "[3]\teval-mlogloss:1.34210\n",
      "[4]\teval-mlogloss:1.28727\n",
      "[5]\teval-mlogloss:1.22472\n",
      "[6]\teval-mlogloss:1.17537\n",
      "[7]\teval-mlogloss:1.13316\n",
      "[8]\teval-mlogloss:1.09554\n",
      "[9]\teval-mlogloss:1.06137\n",
      "[10]\teval-mlogloss:1.03426\n",
      "[11]\teval-mlogloss:1.00681\n",
      "[12]\teval-mlogloss:0.98781\n",
      "[13]\teval-mlogloss:0.96752\n",
      "[14]\teval-mlogloss:0.94506\n",
      "[15]\teval-mlogloss:0.92842\n",
      "[16]\teval-mlogloss:0.91034\n",
      "[17]\teval-mlogloss:0.89583\n",
      "[18]\teval-mlogloss:0.88379\n",
      "[19]\teval-mlogloss:0.87175\n",
      "[20]\teval-mlogloss:0.85425\n",
      "[21]\teval-mlogloss:0.83747\n",
      "[22]\teval-mlogloss:0.82248\n",
      "[23]\teval-mlogloss:0.81498\n",
      "[24]\teval-mlogloss:0.80675\n",
      "[25]\teval-mlogloss:0.80117\n",
      "[26]\teval-mlogloss:0.79405\n",
      "[27]\teval-mlogloss:0.78698\n",
      "[28]\teval-mlogloss:0.78169\n",
      "[29]\teval-mlogloss:0.77943\n",
      "[30]\teval-mlogloss:0.77512\n",
      "[31]\teval-mlogloss:0.76697\n",
      "[32]\teval-mlogloss:0.76054\n",
      "[33]\teval-mlogloss:0.75400\n",
      "[34]\teval-mlogloss:0.75023\n",
      "[35]\teval-mlogloss:0.74764\n",
      "[36]\teval-mlogloss:0.74378\n",
      "[37]\teval-mlogloss:0.73880\n",
      "[38]\teval-mlogloss:0.73338\n",
      "[39]\teval-mlogloss:0.72988\n",
      "[40]\teval-mlogloss:0.72736\n",
      "[41]\teval-mlogloss:0.72313\n",
      "[42]\teval-mlogloss:0.72198\n",
      "[43]\teval-mlogloss:0.72090\n",
      "[44]\teval-mlogloss:0.71660\n",
      "[45]\teval-mlogloss:0.71253\n",
      "[46]\teval-mlogloss:0.71212\n",
      "[47]\teval-mlogloss:0.71068\n",
      "[48]\teval-mlogloss:0.70799\n",
      "[49]\teval-mlogloss:0.70473\n",
      "[50]\teval-mlogloss:0.70292\n",
      "[51]\teval-mlogloss:0.70209\n",
      "[52]\teval-mlogloss:0.69952\n",
      "[53]\teval-mlogloss:0.69806\n",
      "[54]\teval-mlogloss:0.69707\n",
      "[55]\teval-mlogloss:0.69605\n",
      "[56]\teval-mlogloss:0.69466\n",
      "[57]\teval-mlogloss:0.69420\n",
      "[58]\teval-mlogloss:0.69382\n",
      "[59]\teval-mlogloss:0.69308\n",
      "[60]\teval-mlogloss:0.68982\n",
      "[61]\teval-mlogloss:0.68751\n",
      "[62]\teval-mlogloss:0.68561\n",
      "[63]\teval-mlogloss:0.68484\n",
      "[64]\teval-mlogloss:0.68377\n",
      "[65]\teval-mlogloss:0.68333\n",
      "[66]\teval-mlogloss:0.68245\n",
      "[67]\teval-mlogloss:0.68234\n",
      "[68]\teval-mlogloss:0.68163\n",
      "[69]\teval-mlogloss:0.68173\n",
      "[70]\teval-mlogloss:0.67930\n",
      "[71]\teval-mlogloss:0.67874\n",
      "[72]\teval-mlogloss:0.67777\n",
      "[73]\teval-mlogloss:0.67539\n",
      "[74]\teval-mlogloss:0.67541\n",
      "[75]\teval-mlogloss:0.67415\n",
      "[76]\teval-mlogloss:0.67287\n",
      "[77]\teval-mlogloss:0.67285\n",
      "[78]\teval-mlogloss:0.67213\n",
      "[79]\teval-mlogloss:0.67132\n",
      "[80]\teval-mlogloss:0.67151\n",
      "[81]\teval-mlogloss:0.67210\n",
      "[82]\teval-mlogloss:0.67214\n",
      "[83]\teval-mlogloss:0.67285\n",
      "[84]\teval-mlogloss:0.67205\n",
      "[85]\teval-mlogloss:0.67285\n",
      "[86]\teval-mlogloss:0.67226\n",
      "[87]\teval-mlogloss:0.67202\n",
      "[88]\teval-mlogloss:0.67217\n",
      "[89]\teval-mlogloss:0.67177\n",
      "[90]\teval-mlogloss:0.67133\n",
      "[91]\teval-mlogloss:0.67129\n",
      "[92]\teval-mlogloss:0.67202\n",
      "[93]\teval-mlogloss:0.67049\n",
      "[94]\teval-mlogloss:0.66908\n",
      "[95]\teval-mlogloss:0.66831\n",
      "[96]\teval-mlogloss:0.66646\n",
      "[97]\teval-mlogloss:0.66604\n",
      "[98]\teval-mlogloss:0.66620\n",
      "[99]\teval-mlogloss:0.66516\n",
      "[100]\teval-mlogloss:0.66556\n",
      "[101]\teval-mlogloss:0.66469\n",
      "[102]\teval-mlogloss:0.66581\n",
      "[103]\teval-mlogloss:0.66468\n",
      "[104]\teval-mlogloss:0.66481\n",
      "[105]\teval-mlogloss:0.66469\n",
      "[106]\teval-mlogloss:0.66526\n",
      "[107]\teval-mlogloss:0.66505\n",
      "[108]\teval-mlogloss:0.66593\n",
      "[109]\teval-mlogloss:0.66533\n",
      "[110]\teval-mlogloss:0.66403\n",
      "[111]\teval-mlogloss:0.66414\n",
      "[112]\teval-mlogloss:0.66427\n",
      "[113]\teval-mlogloss:0.66428\n",
      "[114]\teval-mlogloss:0.66484\n",
      "[115]\teval-mlogloss:0.66517\n",
      "[116]\teval-mlogloss:0.66465\n",
      "[117]\teval-mlogloss:0.66562\n",
      "[118]\teval-mlogloss:0.66505\n",
      "[119]\teval-mlogloss:0.66439\n",
      "[120]\teval-mlogloss:0.66411\n",
      "[121]\teval-mlogloss:0.66401\n",
      "[122]\teval-mlogloss:0.66382\n",
      "[123]\teval-mlogloss:0.66441\n",
      "[124]\teval-mlogloss:0.66520\n",
      "[125]\teval-mlogloss:0.66487\n",
      "[126]\teval-mlogloss:0.66546\n",
      "[127]\teval-mlogloss:0.66489\n",
      "[128]\teval-mlogloss:0.66556\n",
      "[129]\teval-mlogloss:0.66604\n",
      "[130]\teval-mlogloss:0.66534\n",
      "[131]\teval-mlogloss:0.66507\n",
      "[132]\teval-mlogloss:0.66458\n",
      "[133]\teval-mlogloss:0.66465\n",
      "[134]\teval-mlogloss:0.66391\n",
      "[135]\teval-mlogloss:0.66303\n",
      "[136]\teval-mlogloss:0.66230\n",
      "[137]\teval-mlogloss:0.66179\n",
      "[138]\teval-mlogloss:0.66098\n",
      "[139]\teval-mlogloss:0.66044\n",
      "[140]\teval-mlogloss:0.66058\n",
      "[141]\teval-mlogloss:0.66006\n",
      "[142]\teval-mlogloss:0.65974\n",
      "[143]\teval-mlogloss:0.66040\n",
      "[144]\teval-mlogloss:0.66085\n",
      "[145]\teval-mlogloss:0.66063\n",
      "[146]\teval-mlogloss:0.66066\n",
      "[147]\teval-mlogloss:0.66162\n",
      "[148]\teval-mlogloss:0.66196\n",
      "[149]\teval-mlogloss:0.66211\n",
      "[150]\teval-mlogloss:0.66172\n",
      "[151]\teval-mlogloss:0.66134\n",
      "[152]\teval-mlogloss:0.66082\n",
      "[153]\teval-mlogloss:0.65992\n",
      "[154]\teval-mlogloss:0.65889\n",
      "[155]\teval-mlogloss:0.65897\n",
      "[156]\teval-mlogloss:0.65935\n",
      "[157]\teval-mlogloss:0.65898\n",
      "[158]\teval-mlogloss:0.66023\n",
      "[159]\teval-mlogloss:0.66059\n",
      "[160]\teval-mlogloss:0.66090\n",
      "[161]\teval-mlogloss:0.66030\n",
      "[162]\teval-mlogloss:0.66018\n",
      "[163]\teval-mlogloss:0.65994\n",
      "[164]\teval-mlogloss:0.65967\n",
      "[165]\teval-mlogloss:0.65854\n",
      "[166]\teval-mlogloss:0.65804\n",
      "[167]\teval-mlogloss:0.65772\n",
      "[168]\teval-mlogloss:0.65791\n",
      "[169]\teval-mlogloss:0.65801\n",
      "[170]\teval-mlogloss:0.65694\n",
      "[171]\teval-mlogloss:0.65666\n",
      "[172]\teval-mlogloss:0.65722\n",
      "[173]\teval-mlogloss:0.65782\n",
      "[174]\teval-mlogloss:0.65683\n",
      "[175]\teval-mlogloss:0.65649\n",
      "[176]\teval-mlogloss:0.65736\n",
      "[177]\teval-mlogloss:0.65804\n",
      "[178]\teval-mlogloss:0.65793\n",
      "[179]\teval-mlogloss:0.65867\n",
      "[180]\teval-mlogloss:0.65881\n",
      "[181]\teval-mlogloss:0.65896\n",
      "[182]\teval-mlogloss:0.65895\n",
      "[183]\teval-mlogloss:0.65865\n",
      "[184]\teval-mlogloss:0.65833\n",
      "[185]\teval-mlogloss:0.65803\n",
      "[186]\teval-mlogloss:0.65759\n",
      "[187]\teval-mlogloss:0.65712\n",
      "[188]\teval-mlogloss:0.65691\n",
      "[189]\teval-mlogloss:0.65679\n",
      "[190]\teval-mlogloss:0.65636\n",
      "[191]\teval-mlogloss:0.65618\n",
      "[192]\teval-mlogloss:0.65639\n",
      "[193]\teval-mlogloss:0.65650\n",
      "[194]\teval-mlogloss:0.65652\n",
      "[195]\teval-mlogloss:0.65593\n",
      "[196]\teval-mlogloss:0.65595\n",
      "[197]\teval-mlogloss:0.65630\n",
      "[198]\teval-mlogloss:0.65627\n",
      "[199]\teval-mlogloss:0.65611\n",
      "[200]\teval-mlogloss:0.65632\n",
      "[201]\teval-mlogloss:0.65597\n",
      "[202]\teval-mlogloss:0.65512\n",
      "[203]\teval-mlogloss:0.65480\n",
      "[204]\teval-mlogloss:0.65549\n",
      "[205]\teval-mlogloss:0.65583\n",
      "[206]\teval-mlogloss:0.65553\n",
      "[207]\teval-mlogloss:0.65477\n",
      "[208]\teval-mlogloss:0.65461\n",
      "[209]\teval-mlogloss:0.65428\n",
      "[210]\teval-mlogloss:0.65480\n",
      "[211]\teval-mlogloss:0.65499\n",
      "[212]\teval-mlogloss:0.65456\n",
      "[213]\teval-mlogloss:0.65433\n",
      "[214]\teval-mlogloss:0.65443\n",
      "[215]\teval-mlogloss:0.65390\n",
      "[216]\teval-mlogloss:0.65370\n",
      "[217]\teval-mlogloss:0.65406\n",
      "[218]\teval-mlogloss:0.65442\n",
      "[219]\teval-mlogloss:0.65387\n",
      "[220]\teval-mlogloss:0.65404\n",
      "[221]\teval-mlogloss:0.65417\n",
      "[222]\teval-mlogloss:0.65371\n",
      "[223]\teval-mlogloss:0.65377\n",
      "[224]\teval-mlogloss:0.65378\n",
      "[225]\teval-mlogloss:0.65380\n",
      "[226]\teval-mlogloss:0.65377\n",
      "[227]\teval-mlogloss:0.65371\n",
      "[228]\teval-mlogloss:0.65325\n",
      "[229]\teval-mlogloss:0.65207\n",
      "[230]\teval-mlogloss:0.65238\n",
      "[231]\teval-mlogloss:0.65275\n",
      "[232]\teval-mlogloss:0.65260\n",
      "[233]\teval-mlogloss:0.65198\n",
      "[234]\teval-mlogloss:0.65193\n",
      "[235]\teval-mlogloss:0.65222\n",
      "[236]\teval-mlogloss:0.65130\n",
      "[237]\teval-mlogloss:0.65145\n",
      "[238]\teval-mlogloss:0.65144\n",
      "[239]\teval-mlogloss:0.65117\n",
      "[240]\teval-mlogloss:0.65146\n",
      "[241]\teval-mlogloss:0.65147\n",
      "[242]\teval-mlogloss:0.65144\n",
      "[243]\teval-mlogloss:0.65167\n",
      "[244]\teval-mlogloss:0.65198\n",
      "[245]\teval-mlogloss:0.65298\n",
      "[246]\teval-mlogloss:0.65211\n",
      "[247]\teval-mlogloss:0.65204\n",
      "[248]\teval-mlogloss:0.65195\n",
      "[249]\teval-mlogloss:0.65206\n",
      "[250]\teval-mlogloss:0.65219\n",
      "[251]\teval-mlogloss:0.65260\n",
      "[252]\teval-mlogloss:0.65303\n",
      "[253]\teval-mlogloss:0.65313\n",
      "[254]\teval-mlogloss:0.65298\n",
      "[255]\teval-mlogloss:0.65338\n",
      "[256]\teval-mlogloss:0.65346\n",
      "[257]\teval-mlogloss:0.65311\n",
      "[258]\teval-mlogloss:0.65333\n",
      "[259]\teval-mlogloss:0.65377\n",
      "[260]\teval-mlogloss:0.65349\n",
      "[261]\teval-mlogloss:0.65288\n",
      "[262]\teval-mlogloss:0.65347\n",
      "[263]\teval-mlogloss:0.65394\n",
      "[264]\teval-mlogloss:0.65447\n",
      "[265]\teval-mlogloss:0.65521\n",
      "[266]\teval-mlogloss:0.65464\n",
      "[267]\teval-mlogloss:0.65422\n",
      "[268]\teval-mlogloss:0.65341\n",
      "[269]\teval-mlogloss:0.65219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[270]\teval-mlogloss:0.65189\n",
      "[271]\teval-mlogloss:0.65116\n",
      "[272]\teval-mlogloss:0.65183\n",
      "[273]\teval-mlogloss:0.65191\n",
      "[274]\teval-mlogloss:0.65245\n",
      "[275]\teval-mlogloss:0.65278\n",
      "[276]\teval-mlogloss:0.65242\n",
      "[277]\teval-mlogloss:0.65261\n",
      "[278]\teval-mlogloss:0.65237\n",
      "[279]\teval-mlogloss:0.65281\n",
      "[280]\teval-mlogloss:0.65289\n",
      "[281]\teval-mlogloss:0.65268\n",
      "[282]\teval-mlogloss:0.65369\n",
      "[283]\teval-mlogloss:0.65363\n",
      "[284]\teval-mlogloss:0.65383\n",
      "[285]\teval-mlogloss:0.65353\n",
      "[286]\teval-mlogloss:0.65346\n",
      "[287]\teval-mlogloss:0.65365\n",
      "[288]\teval-mlogloss:0.65347\n",
      "[289]\teval-mlogloss:0.65334\n",
      "[290]\teval-mlogloss:0.65337\n",
      "[291]\teval-mlogloss:0.65355\n",
      "[292]\teval-mlogloss:0.65325\n",
      "[293]\teval-mlogloss:0.65331\n",
      "[294]\teval-mlogloss:0.65333\n",
      "[295]\teval-mlogloss:0.65342\n",
      "[296]\teval-mlogloss:0.65278\n",
      "[297]\teval-mlogloss:0.65282\n",
      "[298]\teval-mlogloss:0.65250\n",
      "[299]\teval-mlogloss:0.65247\n",
      "[300]\teval-mlogloss:0.65234\n",
      "[301]\teval-mlogloss:0.65214\n",
      "[302]\teval-mlogloss:0.65226\n",
      "[303]\teval-mlogloss:0.65209\n",
      "[304]\teval-mlogloss:0.65184\n",
      "[305]\teval-mlogloss:0.65197\n",
      "[306]\teval-mlogloss:0.65225\n",
      "[307]\teval-mlogloss:0.65147\n",
      "[308]\teval-mlogloss:0.65167\n",
      "[309]\teval-mlogloss:0.65121\n",
      "[310]\teval-mlogloss:0.65095\n",
      "[311]\teval-mlogloss:0.65155\n",
      "[312]\teval-mlogloss:0.65152\n",
      "[313]\teval-mlogloss:0.65195\n",
      "[314]\teval-mlogloss:0.65194\n",
      "[315]\teval-mlogloss:0.65134\n",
      "[316]\teval-mlogloss:0.65112\n",
      "[317]\teval-mlogloss:0.65093\n",
      "[318]\teval-mlogloss:0.65144\n",
      "[319]\teval-mlogloss:0.65199\n",
      "[320]\teval-mlogloss:0.65214\n",
      "[321]\teval-mlogloss:0.65124\n",
      "[322]\teval-mlogloss:0.65066\n",
      "[323]\teval-mlogloss:0.65059\n",
      "[324]\teval-mlogloss:0.65105\n",
      "[325]\teval-mlogloss:0.65105\n",
      "[326]\teval-mlogloss:0.65113\n",
      "[327]\teval-mlogloss:0.65145\n",
      "[328]\teval-mlogloss:0.65172\n",
      "[329]\teval-mlogloss:0.65128\n",
      "[330]\teval-mlogloss:0.65156\n",
      "[331]\teval-mlogloss:0.65156\n",
      "[332]\teval-mlogloss:0.65167\n",
      "[333]\teval-mlogloss:0.65141\n",
      "[334]\teval-mlogloss:0.65121\n",
      "[335]\teval-mlogloss:0.65187\n",
      "[336]\teval-mlogloss:0.65194\n",
      "[337]\teval-mlogloss:0.65250\n",
      "[338]\teval-mlogloss:0.65280\n",
      "[339]\teval-mlogloss:0.65345\n",
      "[340]\teval-mlogloss:0.65358\n",
      "[341]\teval-mlogloss:0.65376\n",
      "[342]\teval-mlogloss:0.65375\n",
      "[343]\teval-mlogloss:0.65366\n",
      "[344]\teval-mlogloss:0.65364\n",
      "[345]\teval-mlogloss:0.65361\n",
      "[346]\teval-mlogloss:0.65388\n",
      "[347]\teval-mlogloss:0.65388\n",
      "[348]\teval-mlogloss:0.65380\n",
      "[349]\teval-mlogloss:0.65394\n",
      "[350]\teval-mlogloss:0.65402\n",
      "[351]\teval-mlogloss:0.65364\n",
      "[352]\teval-mlogloss:0.65385\n",
      "[353]\teval-mlogloss:0.65436\n",
      "[354]\teval-mlogloss:0.65428\n",
      "[355]\teval-mlogloss:0.65425\n",
      "[356]\teval-mlogloss:0.65437\n",
      "[357]\teval-mlogloss:0.65426\n",
      "[358]\teval-mlogloss:0.65438\n",
      "[359]\teval-mlogloss:0.65488\n",
      "[360]\teval-mlogloss:0.65497\n",
      "[361]\teval-mlogloss:0.65487\n",
      "[362]\teval-mlogloss:0.65503\n",
      "[363]\teval-mlogloss:0.65463\n",
      "[364]\teval-mlogloss:0.65511\n",
      "[365]\teval-mlogloss:0.65500\n",
      "[366]\teval-mlogloss:0.65446\n",
      "[367]\teval-mlogloss:0.65417\n",
      "[368]\teval-mlogloss:0.65380\n",
      "[369]\teval-mlogloss:0.65393\n",
      "[370]\teval-mlogloss:0.65409\n",
      "[371]\teval-mlogloss:0.65383\n",
      "[372]\teval-mlogloss:0.65416\n",
      "[373]\teval-mlogloss:0.65381\n",
      "[374]\teval-mlogloss:0.65381\n",
      "[375]\teval-mlogloss:0.65405\n",
      "[376]\teval-mlogloss:0.65401\n",
      "[377]\teval-mlogloss:0.65437\n",
      "[378]\teval-mlogloss:0.65426\n",
      "[379]\teval-mlogloss:0.65477\n",
      "[380]\teval-mlogloss:0.65520\n",
      "[381]\teval-mlogloss:0.65493\n",
      "[382]\teval-mlogloss:0.65504\n",
      "[383]\teval-mlogloss:0.65486\n",
      "[384]\teval-mlogloss:0.65509\n",
      "[385]\teval-mlogloss:0.65475\n",
      "[386]\teval-mlogloss:0.65481\n",
      "[387]\teval-mlogloss:0.65472\n",
      "[388]\teval-mlogloss:0.65493\n",
      "[389]\teval-mlogloss:0.65474\n",
      "[390]\teval-mlogloss:0.65495\n",
      "[391]\teval-mlogloss:0.65493\n",
      "[392]\teval-mlogloss:0.65487\n",
      "[393]\teval-mlogloss:0.65479\n",
      "[394]\teval-mlogloss:0.65497\n",
      "[395]\teval-mlogloss:0.65486\n",
      "[396]\teval-mlogloss:0.65489\n",
      "[397]\teval-mlogloss:0.65448\n",
      "[398]\teval-mlogloss:0.65469\n",
      "[399]\teval-mlogloss:0.65477\n",
      "[400]\teval-mlogloss:0.65444\n",
      "[401]\teval-mlogloss:0.65499\n",
      "[402]\teval-mlogloss:0.65503\n",
      "[403]\teval-mlogloss:0.65553\n",
      "[404]\teval-mlogloss:0.65564\n",
      "[405]\teval-mlogloss:0.65609\n",
      "[406]\teval-mlogloss:0.65573\n",
      "[407]\teval-mlogloss:0.65585\n",
      "[408]\teval-mlogloss:0.65558\n",
      "[409]\teval-mlogloss:0.65545\n",
      "[410]\teval-mlogloss:0.65554\n",
      "[411]\teval-mlogloss:0.65533\n",
      "[412]\teval-mlogloss:0.65520\n",
      "[413]\teval-mlogloss:0.65453\n",
      "[414]\teval-mlogloss:0.65472\n",
      "[415]\teval-mlogloss:0.65469\n",
      "[416]\teval-mlogloss:0.65469\n",
      "[417]\teval-mlogloss:0.65448\n",
      "[418]\teval-mlogloss:0.65468\n",
      "[419]\teval-mlogloss:0.65502\n",
      "[420]\teval-mlogloss:0.65526\n",
      "[421]\teval-mlogloss:0.65552\n",
      "[422]\teval-mlogloss:0.65521\n",
      "[423]\teval-mlogloss:0.65526\n"
     ]
    }
   ],
   "source": [
    "model = xgboost.train(params=params_1,dtrain=train_dataset,evals=[(val_dataset, 'eval')],early_stopping_rounds=100,num_boost_round=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f33245",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = feature_extractor.predict(x_test)\n",
    "test_features = test_features.reshape(test_features.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ea679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = xgboost.DMatrix(data=test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4669499",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_dataset)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b49141",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(predictions,y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test,predictions,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fcad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(report).transpose\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cc584e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bb44ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
